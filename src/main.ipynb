{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras as keras\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "src_dir = \"../datasets/ori/\"\n",
    "train_dir = \"../datasets/train/\"\n",
    "val_dir = \"../datasets/validation/\"\n",
    "test_dir = \"../datasets/test/\"\n",
    "categories = ['igneous/', 'metamorphic/', 'sedimentary/']\n",
    "for category in categories:\n",
    "    file_list = os.listdir(src_dir+category)\n",
    "    for n, i in enumerate(file_list[:200]):\n",
    "        img = Image.open(src_dir+category+i)\n",
    "        img_resize = img.resize((150, 150))\n",
    "        img_resize.save(train_dir+category[:-1]+\"_\"+str(n)+\".jpg\", \"JPEG\")\n",
    "    for n, i in enumerate(file_list[200:300]):\n",
    "        img = Image.open(src_dir+category+i)\n",
    "        img_resize = img.resize((150, 150))\n",
    "        img_resize.save(val_dir+category[:-1]+\"_\"+str(n)+\".jpg\", \"JPEG\")\n",
    "    for n, i in enumerate(file_list[300:400]):\n",
    "        img = Image.open(src_dir+category+i)\n",
    "        img_resize = img.resize((150, 150))\n",
    "        img_resize.save(test_dir+category[:-1]+\"_\"+str(n)+\".jpg\", \"JPEG\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_data = np.empty(shape=(1, 150, 150, 3), dtype=np.float64)\n",
    "for i in os.listdir(train_dir):\n",
    "    img = Image.open(train_dir+i)\n",
    "    train_data = np.append(train_data, [np.asarray(img)], axis=0)\n",
    "train_data = np.delete(train_data, [0,0], axis=0)\n",
    "train_data = train_data / 255.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "a = [0 for i in range(200)] + [1 for j in range(200)] + [2 for k in range(200)]\n",
    "train_labels = np.array(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 150, 150, 3) (600,)\n"
     ]
    }
   ],
   "source": [
    "s = np.arange(600)\n",
    "np.random.shuffle(s)\n",
    "train_data = train_data[s]\n",
    "train_labels = train_labels[s]\n",
    "print(train_data.shape, train_labels.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# with tf.device('/CPU:0'):\n",
    "#     inputs = keras.Input(shape=(150, 150, 3,))\n",
    "#     flat = layers.Flatten()(inputs)\n",
    "#     fc1 = layers.Dense(64, activation='relu')(flat)\n",
    "#     fc2 = layers.Dense(128, activation='relu')(fc1)\n",
    "#     fc3 = layers.Dense(256, activation='relu')(fc2)\n",
    "#     output = layers.Dense(3, activation='softmax')(fc3)\n",
    "#     model = Model(inputs=inputs, outputs=output, name=\"FC_Model\")\n",
    "#     model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "# model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# with tf.device('/CPU:0'):\n",
    "#     model.fit(train_data, train_labels, epochs=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 148, 148, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 74, 74, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 74, 74, 64)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 72, 72, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 36, 36, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 36, 36, 128)       0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 34, 34, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 32, 32, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 30, 30, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 15, 15, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 15, 15, 512)       0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 115200)            0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 345603    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,256,387\n",
      "Trainable params: 4,256,387\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(150, 150, 3,))\n",
    "conv1 = layers.Conv2D(64, (3, 3), activation='relu')(inputs)\n",
    "pool1 = layers.MaxPool2D((2, 2))(conv1)\n",
    "drop1 = layers.Dropout(0.4)(pool1)\n",
    "conv2 = layers.Conv2D(128, (3, 3), activation='relu')(drop1)\n",
    "pool2 = layers.MaxPool2D((2, 2))(conv2)\n",
    "drop2 = layers.Dropout(0.4)(pool2)\n",
    "conv3 = layers.Conv2D(256, (3, 3), activation='relu')(drop2)\n",
    "conv4 = layers.Conv2D(512, (3, 3), activation='relu')(conv3)\n",
    "conv5 = layers.Conv2D(512, (3, 3), activation='relu')(conv4)\n",
    "pool3 = layers.MaxPool2D((2, 2))(conv5)\n",
    "drop3 = layers.Dropout(0.2)(pool3)\n",
    "flat = layers.Flatten()(drop3)\n",
    "output = layers.Dense(3, activation='softmax')(flat)\n",
    "model = Model(inputs=inputs, outputs=output, name=\"CNN\")\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 22:28:59.592486: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED\n",
      "2021-12-17 22:28:59.592946: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : NOT_FOUND: No algorithm worked!\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": " No algorithm worked!\n\t [[node CNN/conv2d_3/Conv2D\n (defined at /usr/lib/python3.10/site-packages/keras/layers/convolutional.py:229)\n]] [Op:__inference_train_function_3343]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node CNN/conv2d_3/Conv2D:\nIn[0] IteratorGetNext (defined at /usr/lib/python3.10/site-packages/keras/engine/training.py:859)\t\nIn[1] CNN/conv2d_3/Conv2D/ReadVariableOp:\n\nOperation defined at: (most recent call last)\n>>>   File \"/usr/lib/python3.10/runpy.py\", line 191, in _run_module_as_main\n>>>     msg = \"%s: %s\" % (sys.executable, exc)\n>>> \n>>>   File \"/usr/lib/python3.10/runpy.py\", line 75, in _run_code\n>>>     fname = mod_spec.origin\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 12, in <module>\n>>>     if sys.path[0] == '':\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 844, in launch_instance\n>>>     app = cls.instance(**kwargs)\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 668, in start\n>>>     from ipykernel.trio_runner import TrioRunner\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n>>>     old_loop = None  # type: ignore\n>>> \n>>>   File \"/usr/lib/python3.10/asyncio/base_events.py\", line 589, in run_forever\n>>>     old_agen_hooks = sys.get_asyncgen_hooks()\n>>> \n>>>   File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1845, in _run_once\n>>>     event_list = self._selector.select(timeout)\n>>> \n>>>   File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 443, in process_one\n>>>     t, dispatch, args = self.msg_queue.get_nowait()\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 330, in dispatch_shell\n>>>     return\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 630, in execute_request\n>>>     self.log.error(\"%s\", parent)\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 322, in do_execute\n>>>     if (\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n>>>     raw_cell,\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line -1, in run_cell_async\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_ast_nodes\n>>>     if _async:\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3451, in run_code\n>>>     last_expr = (await self._async_exec(code_obj, self.user_ns))\n>>> \n>>>   File \"/tmp/ipykernel_23880/993773297.py\", line 1, in <module>\n>>>     model.fit(train_data, train_labels, batch_size=32, epochs=30, validation_split=0.2)\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 60, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/engine/training.py\", line 1168, in fit\n>>>     y=y,\n>>> \n>>>   File \"/tmp/__autograph_generated_filegtyzfzy8.py\", line 12, in tf__train_function\n>>>     retval_ = ag__.UndefinedReturnValue()\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/engine/training.py\", line 866, in step_function\n>>>     data = next(iterator)\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/engine/training.py\", line 807, in train_step\n>>>     with tf.GradientTape() as tape:\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 60, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1054, in __call__\n>>>     self._clear_losses()\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 91, in error_handler\n>>>     try:\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/engine/functional.py\", line 452, in call\n>>>     inputs, training=training, mask=mask)\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/engine/functional.py\", line 573, in _run_internal_graph\n>>>     tensor_dict[x_id] = [y] * tensor_usage_count[x_id]\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 60, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1054, in __call__\n>>>     self._clear_losses()\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 91, in error_handler\n>>>     try:\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/layers/convolutional.py\", line 244, in call\n>>>     inputs = tf.pad(inputs, self._compute_causal_padding(inputs))\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/layers/convolutional.py\", line 229, in convolution_op\n>>>     tf_padding = self.padding\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotFoundError\u001B[0m                             Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_23880/993773297.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_labels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m32\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m30\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalidation_split\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/lib/python3.10/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 67\u001B[0;31m       \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     68\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m       \u001B[0;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     56\u001B[0m   \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     57\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 58\u001B[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[1;32m     59\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[1;32m     60\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNotFoundError\u001B[0m:  No algorithm worked!\n\t [[node CNN/conv2d_3/Conv2D\n (defined at /usr/lib/python3.10/site-packages/keras/layers/convolutional.py:229)\n]] [Op:__inference_train_function_3343]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node CNN/conv2d_3/Conv2D:\nIn[0] IteratorGetNext (defined at /usr/lib/python3.10/site-packages/keras/engine/training.py:859)\t\nIn[1] CNN/conv2d_3/Conv2D/ReadVariableOp:\n\nOperation defined at: (most recent call last)\n>>>   File \"/usr/lib/python3.10/runpy.py\", line 191, in _run_module_as_main\n>>>     msg = \"%s: %s\" % (sys.executable, exc)\n>>> \n>>>   File \"/usr/lib/python3.10/runpy.py\", line 75, in _run_code\n>>>     fname = mod_spec.origin\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 12, in <module>\n>>>     if sys.path[0] == '':\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 844, in launch_instance\n>>>     app = cls.instance(**kwargs)\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 668, in start\n>>>     from ipykernel.trio_runner import TrioRunner\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n>>>     old_loop = None  # type: ignore\n>>> \n>>>   File \"/usr/lib/python3.10/asyncio/base_events.py\", line 589, in run_forever\n>>>     old_agen_hooks = sys.get_asyncgen_hooks()\n>>> \n>>>   File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1845, in _run_once\n>>>     event_list = self._selector.select(timeout)\n>>> \n>>>   File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 443, in process_one\n>>>     t, dispatch, args = self.msg_queue.get_nowait()\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 330, in dispatch_shell\n>>>     return\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 630, in execute_request\n>>>     self.log.error(\"%s\", parent)\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 322, in do_execute\n>>>     if (\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n>>>     raw_cell,\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line -1, in run_cell_async\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_ast_nodes\n>>>     if _async:\n>>> \n>>>   File \"/home/joon0725/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3451, in run_code\n>>>     last_expr = (await self._async_exec(code_obj, self.user_ns))\n>>> \n>>>   File \"/tmp/ipykernel_23880/993773297.py\", line 1, in <module>\n>>>     model.fit(train_data, train_labels, batch_size=32, epochs=30, validation_split=0.2)\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 60, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/engine/training.py\", line 1168, in fit\n>>>     y=y,\n>>> \n>>>   File \"/tmp/__autograph_generated_filegtyzfzy8.py\", line 12, in tf__train_function\n>>>     retval_ = ag__.UndefinedReturnValue()\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/engine/training.py\", line 866, in step_function\n>>>     data = next(iterator)\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/engine/training.py\", line 807, in train_step\n>>>     with tf.GradientTape() as tape:\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 60, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1054, in __call__\n>>>     self._clear_losses()\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 91, in error_handler\n>>>     try:\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/engine/functional.py\", line 452, in call\n>>>     inputs, training=training, mask=mask)\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/engine/functional.py\", line 573, in _run_internal_graph\n>>>     tensor_dict[x_id] = [y] * tensor_usage_count[x_id]\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 60, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1054, in __call__\n>>>     self._clear_losses()\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 91, in error_handler\n>>>     try:\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/layers/convolutional.py\", line 244, in call\n>>>     inputs = tf.pad(inputs, self._compute_causal_padding(inputs))\n>>> \n>>>   File \"/usr/lib/python3.10/site-packages/keras/layers/convolutional.py\", line 229, in convolution_op\n>>>     tf_padding = self.padding\n>>> "
     ]
    }
   ],
   "source": [
    "model.fit(train_data, train_labels, batch_size=32, epochs=30, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 16:00:14.170883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 16:00:14.171075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 16:00:14.196175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 16:00:14.196368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 16:00:14.196652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 16:00:14.196817: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 16:00:14.197320: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-17 16:00:14.314952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 16:00:14.315127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 16:00:14.315265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 16:00:14.315395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 16:00:14.315522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 16:00:14.315650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 16:00:14.807187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 16:00:14.807398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 16:00:14.807538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 16:00:14.807676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 16:00:14.807809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 16:00:14.807934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10268 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2021-12-17 16:00:14.808181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-17 16:00:14.808298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10420 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\n",
      "2021-12-17 16:00:14.808506: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 3s 0us/step\n",
      "58900480/58889256 [==============================] - 3s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.VGG16(input_shape=(150, 150, 3),\n",
    "                                      include_top=False,\n",
    "                                      weights='imagenet')\n",
    "base_model.trainable = False\n",
    "base_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               2097408   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,230,531\n",
      "Trainable params: 2,230,531\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "top_model = keras.models.Sequential()\n",
    "top_model.add(layers.Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(layers.Dense(256, activation='relu'))\n",
    "top_model.add(layers.Dense(512, activation='relu'))\n",
    "top_model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "top_model.load_weights(top_model)\n",
    "\n",
    "top_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When setting `include_top=True` and loading `imagenet` weights, `input_shape` should be (224, 224, 3).  Received: input_shape=(150, 150, 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_130738/3159202201.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeras\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mapplications\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mapplications\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mVGG16\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweights\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'imagenet'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_shape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m150\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m150\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m3\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mtop_model\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSequential\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mtop_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mFlatten\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_shape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moutput_shape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mtop_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDense\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m256\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mactivation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'relu'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.9/site-packages/keras/applications/vgg16.py\u001B[0m in \u001B[0;36mVGG16\u001B[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001B[0m\n\u001B[1;32m    126\u001B[0m                      f'Received `classes={classes}`')\n\u001B[1;32m    127\u001B[0m   \u001B[0;31m# Determine proper input shape\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 128\u001B[0;31m   input_shape = imagenet_utils.obtain_input_shape(\n\u001B[0m\u001B[1;32m    129\u001B[0m       \u001B[0minput_shape\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    130\u001B[0m       \u001B[0mdefault_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m224\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.9/site-packages/keras/applications/imagenet_utils.py\u001B[0m in \u001B[0;36mobtain_input_shape\u001B[0;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001B[0m\n\u001B[1;32m    347\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0minput_shape\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    348\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0minput_shape\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mdefault_shape\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 349\u001B[0;31m         raise ValueError('When setting `include_top=True` '\n\u001B[0m\u001B[1;32m    350\u001B[0m                          \u001B[0;34m'and loading `imagenet` weights, '\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    351\u001B[0m                          \u001B[0;34mf'`input_shape` should be {default_shape}.  '\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: When setting `include_top=True` and loading `imagenet` weights, `input_shape` should be (224, 224, 3).  Received: input_shape=(150, 150, 3)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import applications\n",
    "model = applications.VGG16(weights='imagenet', input_shape=(150, 150, 3))\n",
    "top_model = keras.Sequential()\n",
    "top_model.add(layers.Flatten(input_shape=model.output_shape[1:]))\n",
    "top_model.add(layers.Dense(256, activation='relu'))\n",
    "top_model.add(layers.Dense(2, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}